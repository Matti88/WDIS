{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDIS: Service for OCpR: Areas of Opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_descriptions_and_non_tags(df):\n",
    "    sku_desc_filter_out = lambda x: 'sku_desc' not in x\n",
    "    sku_qty_tag = lambda x: not( ('sku' not in x) and ('qty' not in x) and ('tag' not in x))\n",
    "    cols_non_desc =  list(filter(sku_desc_filter_out, df.columns.to_list()))\n",
    "    \n",
    "    cols_non_desc =  list(filter(sku_qty_tag, cols_non_desc))\n",
    "    \n",
    "    \n",
    "    return copy.copy(df[cols_non_desc])\n",
    "\n",
    "def filter_out_tags(df):\n",
    "    sku_w_tags = lambda x: 'tag' not in x\n",
    "    cols_non_desc =  list(filter(sku_w_tags, df.columns.to_list()))\n",
    "    return copy.copy(df[cols_non_desc])\n",
    "\n",
    "def keep_tags(df):\n",
    "    sku_w_tags = lambda x: 'tag' in x\n",
    "    cols_tags =  list(filter(sku_w_tags, df.columns.to_list()))\n",
    "    return copy.copy(df[cols_tags])\n",
    "\n",
    "\n",
    "def column_renamer(df, sheet_name):\n",
    "    df.columns = [ sheet_name+'_' + x if (('sku' in x) or ('qty' in x)) else x for x in  df.columns.to_list()]\n",
    "    return df\n",
    "\n",
    "def dataframes_splitter(path_to_the_file = r'.\\uploads\\VxRail_E560N.xls', list_for_splits=['Street_Prices', 'List_Prices']):\n",
    "    OCpR_dfs, Prices_dfs = [], []\n",
    "    \n",
    "    excel_ = pd.ExcelFile(path_to_the_file)\n",
    "\n",
    "    worksheets_names = excel_.sheet_names\n",
    "    for ws_ in worksheets_names:\n",
    "\n",
    "        if (ws_ in list_for_splits) or ('Prices_' in ws_) :\n",
    "            some_details = pd.read_excel(excel_, sheet_name=ws_)\n",
    "            some_details.title = ws_\n",
    "            Prices_dfs.append(some_details )\n",
    "        else:\n",
    "            df_comb = filter_out_descriptions_and_non_tags(pd.read_excel(excel_, sheet_name=ws_))\n",
    "            \n",
    "            OCpR_dfs.append(column_renamer(df_comb, ws_))\n",
    "    \n",
    "    return OCpR_dfs, Prices_dfs\n",
    "\n",
    "\n",
    "def common_tags(df_l, df_r):\n",
    "    left_ = df_l.columns.to_list()\n",
    "    rigth_ = df_r.columns.to_list()\n",
    "    return list(set(left_).intersection(rigth_))\n",
    "\n",
    "def loop_thru_dataframes(df_list, howhow='inner'):\n",
    "    ocpr_df = pd.DataFrame()\n",
    "    counter =  1\n",
    "    for d_ in df_list:\n",
    "        if counter == 1:\n",
    "            ocpr_df = d_\n",
    "            counter += 1\n",
    "        else:\n",
    "            cmmn_tags_list = common_tags(ocpr_df, d_)\n",
    "            if len(cmmn_tags_list) == 0:\n",
    "                ocpr_df['comKey'] = 1\n",
    "                d_['comKey'] = 1\n",
    "                ocpr_df = pd.merge( ocpr_df, d_, on ='comKey', how=howhow)\n",
    "                ocpr_df = ocpr_df.drop(columns=['comKey'])\n",
    "            else:\n",
    "                ocpr_df = pd.merge( ocpr_df, d_, on=cmmn_tags_list ,how=howhow)    \n",
    "    return ocpr_df\n",
    "\n",
    "def order_columns(df):\n",
    "    sku_and_qty = lambda x : ('sku' in x) or ('qty' in x)\n",
    "    tag = lambda x : ('tag' in x) \n",
    "    cols_ = df.columns.to_list()\n",
    "    return  pd.concat( [ df[list(filter(sku_and_qty, cols_))], df[list(filter(tag, cols_))] ], axis=1)\n",
    "\n",
    "\n",
    "def OCpR_stacker(df):\n",
    "    \n",
    "    OCpR_stackable = filter_out_tags(df)\n",
    "    OCpR_conf_tags = keep_tags(df)\n",
    "    list_to_add_as_code =[x+1 for x in  OCpR_conf_tags.index.to_list().copy()]     \n",
    "    OCpR_conf_tags['code'] = list_to_add_as_code\n",
    "    \n",
    "    rows_to_stack = [] \n",
    "    for row in OCpR_stackable.iterrows():\n",
    "        conf_number = row[0]\n",
    "        example = row\n",
    "        col_ = 1\n",
    "        elements_to_stuck = []\n",
    "        for elem_ in row[1]: \n",
    "\n",
    "            if col_%2 == 0:\n",
    "                                \n",
    "                elements_to_stuck.append(elem_)\n",
    "                elements_to_stuck.append(conf_number+1)\n",
    "                rows_to_stack.append(elements_to_stuck)\n",
    "                elements_to_stuck = []\n",
    "            else:\n",
    "                elements_to_stuck.append(elem_)\n",
    "\n",
    "            col_ +=1\n",
    "    return pd.DataFrame(rows_to_stack, columns=['SKU', 'qty','code']), OCpR_conf_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnalysisDF(path_to_the_file__ ):\n",
    "\n",
    "    dfs, details_dfs = dataframes_splitter(path_to_the_file = path_to_the_file__)\n",
    "    OCpR = loop_thru_dataframes(dfs)\n",
    "    OCpR_staked, OCpR_tags = OCpR_stacker(OCpR)\n",
    "    details_dfs.insert(0,OCpR_staked)\n",
    "    df_ca = loop_thru_dataframes(details_dfs, howhow='left')\n",
    "\n",
    "    #ListPrices\n",
    "    df_ca['q_by_Lp'] = df_ca['List_Price'] * df_ca['qty']\n",
    "    df_ca = df_ca.fillna(0.0)\n",
    "    Conf_List_prices = df_ca[['code','q_by_Lp']].groupby('code').sum()\n",
    "    Conf_List_prices['code'] = Conf_List_prices.index\n",
    "    Conf_List_prices.index = Conf_List_prices.index.rename('index')\n",
    "\n",
    "    #StreetPrices\n",
    "    df_ca['q_by_Sp'] = df_ca['Street_Price'] * df_ca['qty']\n",
    "    df_ca = df_ca.fillna(0.0)\n",
    "    Conf_Street_prices = df_ca[['code','q_by_Sp']].groupby('code').sum()\n",
    "    Conf_Street_prices['code'] = Conf_List_prices.index\n",
    "    Conf_Street_prices.index = Conf_Street_prices.index.rename('index')\n",
    "\n",
    "    final_df = pd.merge(OCpR_tags,Conf_List_prices, on='code', how='inner')\n",
    "\n",
    "    final_df = pd.merge(final_df,Conf_Street_prices, on='code', how='inner')\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADOT_dfs(MyCompany=r'./uploads/MyCompany.xls', Competitor=r'./uploads/Competitor.xls'):\n",
    "    '''\n",
    "    Process Function: \n",
    "    '''\n",
    "    #basic DataFrames\n",
    "    Competitor0 = AnalysisDF(MyCompany)\n",
    "    Competitor1 = AnalysisDF(Competitor)\n",
    "\n",
    "    #clearing out the configuration code in a very complicated way\n",
    "    Comp0 = pd.concat([Competitor0[list(filter(lambda x: 'tag' in x,  Competitor0.columns))], Competitor0[['q_by_Lp','q_by_Sp']] ] , axis=1)\n",
    "    Comp1 = pd.concat([Competitor1[list(filter(lambda x: 'tag' in x,  Competitor1.columns))], Competitor1[['q_by_Lp','q_by_Sp']] ] , axis=1)\n",
    "\n",
    "    #summarying all the combinations of tags against the average prices related to those \n",
    "    Comp0_grouped = Comp0.groupby(list(filter(lambda x: 'tag' in x,  Comp0.columns))).mean().reset_index() \n",
    "    Comp1_grouped = Comp1.groupby(list(filter(lambda x: 'tag' in x,  Comp1.columns))).mean().reset_index() \n",
    "\n",
    "    return Competitor0, Competitor1, Comp0, Comp1, Comp0_grouped, Comp1_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyCompany_LP_Advantage, MyCompany_SP_Advantage, _,_, Competitor_SP_Advantage, Competitor_LP_Advantage = ADOT_dfs()\n",
    "\n",
    "path_to_the_file__ = r'./uploads/MyCompany.xls'\n",
    "dfs, details_dfs = dataframes_splitter(path_to_the_file = path_to_the_file__)\n",
    "OCpR = loop_thru_dataframes(dfs)\n",
    "OCpR_staked, OCpR_tags = OCpR_stacker(OCpR)\n",
    "details_dfs.insert(0,OCpR_staked)\n",
    "df_ca = loop_thru_dataframes(details_dfs, howhow='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-4d471cb8a2c5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-4d471cb8a2c5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pd.merge( OCpR_tags, MyCompany_LP_Advantage, on\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "pd.merge( OCpR_tags, MyCompany_LP_Advantage, on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPU_level_tag</th>\n",
       "      <th>cache_limit_tag</th>\n",
       "      <th>vSAN_level_tag</th>\n",
       "      <th>N_years_service_tag</th>\n",
       "      <th>code</th>\n",
       "      <th>q_by_Lp</th>\n",
       "      <th>q_by_Sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gold</td>\n",
       "      <td>single</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12903.0</td>\n",
       "      <td>5162.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gold</td>\n",
       "      <td>single</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12902.0</td>\n",
       "      <td>5161.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gold</td>\n",
       "      <td>single</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12903.0</td>\n",
       "      <td>5162.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gold</td>\n",
       "      <td>single</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12902.0</td>\n",
       "      <td>5161.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gold</td>\n",
       "      <td>single</td>\n",
       "      <td>Enterprise</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12759.0</td>\n",
       "      <td>5119.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CPU_level_tag cache_limit_tag vSAN_level_tag  N_years_service_tag  code  \\\n",
       "0          Gold          single     Enterprise                    3     1   \n",
       "1          Gold          single     Enterprise                    3     2   \n",
       "2          Gold          single     Enterprise                    3     3   \n",
       "3          Gold          single     Enterprise                    3     4   \n",
       "4          Gold          single     Enterprise                    3     5   \n",
       "\n",
       "   q_by_Lp  q_by_Sp  \n",
       "0  12903.0   5162.7  \n",
       "1  12902.0   5161.8  \n",
       "2  12903.0   5162.7  \n",
       "3  12902.0   5161.8  \n",
       "4  12759.0   5119.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyCompany_LP_Advantage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_data_extract = details_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secretFormulaGeneratingSeuquencesSalesData(list_of_conf_code):\n",
    "    import random\n",
    "\n",
    "    weight_for_confs = []\n",
    "    months = [1,2,3,4,5]\n",
    "    percentages = [0.3,0.2, 0.25]\n",
    "    month_outcome = {}\n",
    "\n",
    "    for conf_ in list_of_conf_code:\n",
    "        weight_for_confs.append(random.betavariate(1.3,5))\n",
    "\n",
    "    norm = [float(i)/sum(weight_for_confs) for i in weight_for_confs]\n",
    "    prob_conf = sorted(list(zip(norm, list_of_conf_code)), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    for month_ in months:\n",
    "        selected_items = []\n",
    "        rangeSelected = prob_conf[0:random.randint(100,120)]\n",
    "        for i in range(int(round(len(rangeSelected) * random.choice(percentages),0))):\n",
    "            selected_items.append(random.choice(rangeSelected))\n",
    "        month_outcome[month_] = selected_items\n",
    "        \n",
    "    return month_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_conf_code = details_dfs[0]['code'].unique().tolist()\n",
    "dict_month_sales = secretFormulaGeneratingSeuquencesSalesData(list_of_conf_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSales = None\n",
    "for month_ in dict_month_sales.keys():\n",
    "    ord_seq = 1\n",
    "    for item in dict_month_sales[month_]:\n",
    "        singleOrder = order_data_extract[order_data_extract['code'] == item[1]].copy()\n",
    "        singleOrder['Month']  = month_\n",
    "        singleOrder['OrdSeq'] = ord_seq\n",
    "        ord_seq += 1\n",
    "        if dataSales is None:\n",
    "            dataSales = singleOrder\n",
    "        else:\n",
    "            dataSales = pd.concat([dataSales , singleOrder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataSales.to_excel('.\\sales.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the association to the advantage DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string_sum as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MC_Bundle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-51e28f01f12f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msome_Object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloop_two_lists_rayon\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMC_Bundle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAllSKUs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOrders_5020\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAllSKUs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'MC_Bundle' is not defined"
     ]
    }
   ],
   "source": [
    "some_Object = sr.loop_two_lists_rayon( list(MC_Bundle.AllSKUs),list(Orders_5020.AllSKUs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
